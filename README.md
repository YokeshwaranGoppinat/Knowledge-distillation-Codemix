# Knowledge Distillation for Code-Mixed Sentiment Classification

This repository implements **teacherâ€“student knowledge distillation** for sentiment classification on **Tamilâ€“English** and **Hindiâ€“English** code-mixed text.  
It includes preprocessing, teacher training, multiple student models, evaluation, and a full dataset for reproducibility.

---

# ğŸ“˜ Overview

Modern Transformer models perform strongly on noisy code-mixed text, but they are expensive to deploy.  
**Knowledge Distillation (KD)** compresses a large model (teacher) into a much smaller student model with minimal accuracy drop.

This project trains:
- A full-size **Teacher Transformer**
- Six distilled **Student models**:
  - Baseline
  - Soft-label distillation
  - Hidden-state distillation
  - Embedding distillation
  - Attention distillation
  - Full multi-signal distillation

Each variant is analyzed in `ResultsSummary.ipynb`.

---

# ğŸ“‚ Project Structure

```
Data/
  Tamil_codemix/
    tam_train.csv
    tam_val.csv
    tam_test.csv
  Hindi_codemix/
    hin_train.csv
    hin_val.csv
    hin_test.csv

src/
  dataset_utils.py
  trainer.py
  model_utils.py
  utils.py

notebooks/
  DataPrep.ipynb
  TeacherTrainer.ipynb
  Student_Baseline.ipynb
  Student_Soft.ipynb
  Student_Hidden.ipynb
  Student_Embedding.ipynb
  Student_Attention.ipynb
  Student_Full.ipynb
  ResultsSummary.ipynb

smoke_test.py
run_colab.ipynb
requirements.txt
LICENSE
```

---

# ğŸ“Š Dataset (Included)

This repository **includes the dataset** used for training and evaluation:

### Tamil Code-Mixed Sentiment
- `tam_train.csv`  
- `tam_val.csv`  
- `tam_test.csv`

### Hindi Code-Mixed Sentiment
- `hin_train.csv`  
- `hin_val.csv`  
- `hin_test.csv`

Each CSV has:
- `review` â€” text (code-mixed sentence)  
- `label` â€” sentiment class (0/1)

These files are small and safe to store directly in the repository.

---

# ğŸš€ Running the Project (Colab Recommended)

### 1. Open **run_colab.ipynb**
Run all cells.  
This will:
- Install dependencies  
- Run `smoke_test.py` (30-second functional test)  
- Detect the dataset under `Data/`  
- Confirm tokenization â†’ dataloading â†’ model forward pass  

### 2. Run full experiments
Open `notebooks/` and run:

- `TeacherTrainer.ipynb` â†’ train teacher  
- `Student_*.ipynb` â†’ train student models  
- `ResultsSummary.ipynb` â†’ generate comparison plots  

---

# ğŸ§ª Student Model Variants

| Variant | Description |
|--------|-------------|
| Baseline | Trains from scratch without teacher |
| Soft | Distills only soft probabilities |
| Hidden | Matches hidden-layer activations |
| Embedding | Matches token embeddings |
| Attention | Matches attention matrices |
| Full | All losses combined for strongest student |

---

# ğŸ“ˆ Results Summary

The strongest distilled model achieves performance close to the teacher with **significantly fewer parameters**, making it suitable for deployment on edge devices.


---

# ğŸ“ License
MIT License

