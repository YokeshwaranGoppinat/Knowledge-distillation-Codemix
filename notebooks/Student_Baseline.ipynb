{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOGe2jdkkmTWvh0mXrx/oLS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "vkfMHBdXM8d_",
        "outputId": "9d0d477e-fa2c-46a3-ef53-53c52234a337"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-413452098.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ===========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -q transformers datasets evaluate accelerate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     case = d.expect([\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(self, pattern, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mcompiled_pattern_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_pattern_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         return self.expect_list(compiled_pattern_list,\n\u001b[0m\u001b[1;32m    355\u001b[0m                 timeout, searchwindowsize, async_)\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpect_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     def expect_exact(self, pattern_list, timeout=-1, searchwindowsize=-1,\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincoming\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Keep reading until exception or return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ===========================\n",
        "# Student training (baseline, patched for 4-epoch teacher)\n",
        "# Saves results with \"_teacher4epoch\" in directory name\n",
        "# ===========================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!pip install -q transformers datasets evaluate accelerate\n",
        "\n",
        "# imports\n",
        "import os, gc, warnings, numpy as np, torch, pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from datasets import Dataset, DatasetDict, Value\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification, AutoConfig,\n",
        "    Trainer, TrainingArguments, DataCollatorWithPadding, set_seed\n",
        ")\n",
        "import evaluate\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "set_seed(42)\n",
        "\n",
        "import os, random\n",
        "\n",
        "def project_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "project_seed(42)\n",
        "\n",
        "# ---------- Paths ----------\n",
        "DRIVE_BASE = \"/content/drive/MyDrive/Colab Notebooks/CodeMix\"\n",
        "train_csv = os.path.join(DRIVE_BASE, \"train.csv\")\n",
        "val_csv   = os.path.join(DRIVE_BASE, \"val.csv\")\n",
        "test_csv  = os.path.join(DRIVE_BASE, \"test.csv\")\n",
        "\n",
        "# use new teacher directory\n",
        "teacher_base_dir = os.path.join(DRIVE_BASE, \"results_teacher_4epoch\")\n",
        "RESULTS_DIR = os.path.join(DRIVE_BASE, \"results_students\")\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# sanity checks\n",
        "for p in (train_csv, val_csv, test_csv):\n",
        "    if not os.path.exists(p):\n",
        "        raise FileNotFoundError(f\"Missing split file: {p}\")\n",
        "if not os.path.isdir(teacher_base_dir):\n",
        "    raise FileNotFoundError(f\"Teacher folder not found: {teacher_base_dir}\")\n",
        "\n",
        "# ---------- Teacher detection ----------\n",
        "def detect_teacher_folder(base_dir):\n",
        "    model_dir = os.path.join(base_dir, \"model\")\n",
        "    if os.path.isdir(model_dir) and \"config.json\" in os.listdir(model_dir):\n",
        "        return model_dir\n",
        "    if \"config.json\" in os.listdir(base_dir):\n",
        "        return base_dir\n",
        "    ckpts = [os.path.join(base_dir, d) for d in os.listdir(base_dir) if d.startswith(\"checkpoint\")]\n",
        "    ckpts = [d for d in ckpts if os.path.isdir(d)]\n",
        "    if ckpts:\n",
        "        return max(ckpts, key=os.path.getmtime)\n",
        "    return None\n",
        "\n",
        "teacher_path = detect_teacher_folder(teacher_base_dir)\n",
        "if teacher_path is None:\n",
        "    raise FileNotFoundError(f\"Could not locate teacher model in {teacher_base_dir}\")\n",
        "print(\"Using teacher from:\", teacher_path)\n",
        "\n",
        "# ---------- Load dataset ----------\n",
        "train_df = pd.read_csv(train_csv)\n",
        "val_df   = pd.read_csv(val_csv)\n",
        "test_df  = pd.read_csv(test_csv)\n",
        "print(\"Loaded splits:\", len(train_df), len(val_df), len(test_df))\n",
        "\n",
        "dataset = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(train_df.reset_index(drop=True)),\n",
        "    \"validation\": Dataset.from_pandas(val_df.reset_index(drop=True)),\n",
        "    \"test\": Dataset.from_pandas(test_df.reset_index(drop=True)),\n",
        "})\n",
        "\n",
        "CHECKPOINT = \"distilbert-base-multilingual-cased\"\n",
        "MAX_LEN = 64\n",
        "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
        "\n",
        "def tokenize_batch(batch):\n",
        "    return tokenizer(batch[\"review\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
        "\n",
        "dataset = dataset.map(tokenize_batch, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
        "dataset[\"train\"] = dataset[\"train\"].add_column(\"label\", train_df[\"label\"].astype(int).tolist())\n",
        "dataset[\"validation\"] = dataset[\"validation\"].add_column(\"label\", val_df[\"label\"].astype(int).tolist())\n",
        "dataset[\"test\"] = dataset[\"test\"].add_column(\"label\", test_df[\"label\"].astype(int).tolist())\n",
        "\n",
        "# keep expected cols\n",
        "keep_cols = [\"input_ids\", \"attention_mask\", \"label\"]\n",
        "for split in dataset.keys():\n",
        "    to_remove = [c for c in dataset[split].column_names if c not in keep_cols]\n",
        "    if to_remove: dataset[split] = dataset[split].remove_columns(to_remove)\n",
        "    dataset[split] = dataset[split].cast_column(\"label\", Value(\"int64\"))\n",
        "dataset.set_format(type=\"torch\")\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# ---------- Metrics ----------\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    if isinstance(logits, tuple): logits = logits[0]\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"macro_f1\": f1_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
        "    }\n",
        "\n",
        "# ---------- Student Config ----------\n",
        "num_student_layers = 2   # adjust layer count here\n",
        "seed = 42\n",
        "\n",
        "student_config = AutoConfig.from_pretrained(\n",
        "    CHECKPOINT,\n",
        "    num_labels=2,\n",
        "    num_hidden_layers=num_student_layers,\n",
        "    output_hidden_states=True,\n",
        "    output_attentions=True\n",
        ")\n",
        "\n",
        "# baseline = no teacher guidance\n",
        "DISTILL_TYPE = \"baseline\"\n",
        "\n",
        "# clear any old globals\n",
        "for n in [\"trainer\",\"student\",\"teacher_loaded\"]:\n",
        "    if n in globals():\n",
        "        del globals()[n]\n",
        "gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "# ---------- DistillTrainer ----------\n",
        "class DistillTrainer(Trainer):\n",
        "    def __init__(self, *args, distill_type=\"baseline\", **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.distill_type = distill_type\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs.loss\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# ---------- Training Args ----------\n",
        "PER_DEVICE_BATCH = 4\n",
        "GRAD_ACCUM = 2\n",
        "EPOCHS = 2\n",
        "LR = 2e-5\n",
        "\n",
        "# patched run name (with teacher4epoch marker)\n",
        "run_name = f\"student_{DISTILL_TYPE}_layers{num_student_layers}_seed{seed}_teacher4epoch\"\n",
        "output_dir = os.path.join(RESULTS_DIR, run_name)\n",
        "\n",
        "def make_train_args(output_dir, **kwargs):\n",
        "    ta_kwargs = dict(kwargs)\n",
        "    if \"evaluation_strategy\" in TrainingArguments.__init__.__code__.co_varnames:\n",
        "        if \"eval_strategy\" in ta_kwargs:\n",
        "            ta_kwargs[\"evaluation_strategy\"] = ta_kwargs.pop(\"eval_strategy\")\n",
        "    else:\n",
        "        if \"evaluation_strategy\" in ta_kwargs:\n",
        "            ta_kwargs[\"eval_strategy\"] = ta_kwargs.pop(\"evaluation_strategy\")\n",
        "    return TrainingArguments(output_dir=output_dir, **ta_kwargs)\n",
        "\n",
        "train_args = make_train_args(\n",
        "    output_dir=output_dir,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    per_device_train_batch_size=PER_DEVICE_BATCH,\n",
        "    per_device_eval_batch_size=PER_DEVICE_BATCH,\n",
        "    gradient_accumulation_steps=GRAD_ACCUM,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    learning_rate=LR,\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "student = AutoModelForSequenceClassification.from_config(student_config).to(device)\n",
        "\n",
        "trainer = DistillTrainer(\n",
        "    model=student,\n",
        "    args=train_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    distill_type=DISTILL_TYPE\n",
        ")\n",
        "\n",
        "print(\"Starting baseline training | layers =\", num_student_layers)\n",
        "trainer.train()\n",
        "\n",
        "# ---------- Evaluate & Save ----------\n",
        "res = trainer.evaluate(dataset[\"test\"])\n",
        "print(\"Baseline student test results:\", res)\n",
        "\n",
        "trainer.save_model(output_dir)\n",
        "print(\"Saved baseline student ->\", output_dir)\n",
        "\n",
        "# cleanup\n",
        "trainer.model.to(\"cpu\")\n",
        "gc.collect(); torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0_VfLvoPOwcE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}